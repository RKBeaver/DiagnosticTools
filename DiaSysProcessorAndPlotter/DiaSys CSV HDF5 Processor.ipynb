{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imported Libraries\n",
    "import numpy as np # Used for generating the Dataset Arrays\n",
    "import os # Used for generating file names and dictionarys. \n",
    "from os.path import isfile, join # Used for generating file names and dictionarys. \n",
    "import math # Used for min and max Y axis values. \n",
    "import h5py # Used for saving the output HDF5 File. \n",
    "from datetime import date # Date used in output file additional information. \n",
    "from scipy import signal as signal # Used for Filter. \n",
    "\n",
    "\n",
    "Version = 2         # version number of the script\n",
    "\n",
    "\n",
    "#Setting base directory for Python Script\n",
    "\n",
    "#os.chdir(os.path.dirname(os.path.abspath(__file__))) # UN-HASH WHEN CONVERTED TO .PY SCRIPT. Used to set base directory in python terminal to enable relative input and output folder names to be used. \n",
    "\n",
    "\n",
    "## FUNCTIONS\n",
    "\n",
    "def InputVariableNumberChecker(Value,Defaultvalue): # Primarily used with a filter window parameter with a default arugment. Checks that the value inputted is a integer. If not the default argument is used. \n",
    "    try: # try to see if the value can be converted to a integer. If it can the function just returns the input value\n",
    "        int(Value) \n",
    "        return Value    \n",
    "    except ValueError: # if the above returns an error it outputs the default argument value as the function output. \n",
    "        print(f\"Suitable value not inputted. Default of {Defaultvalue} is used instead\")\n",
    "        return Defaultvalue\n",
    "\n",
    "def NumberCheck(Input): # Checks that the value inputted it actually an integer. If not continues to ask until a Integer is inputted. \n",
    "    \n",
    "    for ListItem in Input: # cycles through all the seperate elements in the list argument\n",
    "        try:\n",
    "            int(ListItem) # try to see if the value can be converted to a integer. If it can the function cycles to the next item in the list. \n",
    "            \n",
    "        except ValueError: # if the above returns an error it asks again for the user to input a correct number. It then asks for a whole new list and re-initilizes the checking function. It then outputs the updated/corrected input list. \n",
    "            ColumnInputString = input(\"A non-integer or space was inputted. Numbers seperated by spaces only! Try again ->   \")\n",
    "            ColumnsToProcess = ColumnInputString.split(\" \")\n",
    "            Input = NumberCheck(ColumnsToProcess) # performs the NumberCheck function again to confirm that a number was inputted the second time. \n",
    "    \n",
    "# I wonder if this really works if taken to the worst case. First item fails. It asks for an updated list. It then completes with a new list. Does it then cycle to the oringial second value in the first un-updated list? \n",
    "\n",
    "    return Input\n",
    "\n",
    "def SamplePeriodFunction(File): #returns the sample time by reading the CSV time stamps and calculating the difference. scaled to seconds. Float value. \n",
    "    x = open(\"./%s\"%(File), \"r\") # opens the csv file for reading\n",
    "    SP = [] # defining sampledata as a list for the initial extraction of the data\n",
    "    count = 0 # Defining the count for the while loop\n",
    "    while count<=2: # while the count is below 2 do the following. This function results in SP containing two time entries within a list. \n",
    "        if count==0: # if the count is still 0 - ie the first line \n",
    "            x.readline() # read the line (so that python moves onto the next line on the next loop)\n",
    "            count+=1 # add 1 to the count so that the else function is used next time\n",
    "        else:\n",
    "            count+=1 # add to the count\n",
    "            A = x.readline() # read the next line and assign it to the string A\n",
    "            n = 0 # another counter for the FOR loop - used for indexing purposes in the .append line below. \n",
    "            for a in A: # for every character in the string A do the following\n",
    "                if a==\";\": # if the character is the delimiter use the n counter to scrape the previous time data away\n",
    "                    SP.append(int(A[n-9:n-3])) # extracts the time data away, note the indexing may need changing later on. Int() changes the string to an int. adds the value to the ST list defined above.\n",
    "                    break # stop the loop from happening again - function errors if run again. \n",
    "                else:\n",
    "                    n+=1 # add one to the counter for the next character to be accessed\n",
    "            \n",
    "    x.close() # close the file. important. \n",
    "    SP = SP[1] - SP[0] #calculates the difference. Converts list to int\n",
    "    SP = float(SP / 1000000) #scaled to seconds. converts int to float value.  \n",
    "    return SP # return the float ST as the output of the function. \n",
    "\n",
    "def TimeArray(): # Generating an time array for the first column in the DataFrame. Finds the Sample Period, Length of the data array (in terms of cells) and then generates a Time Array based of those values. \n",
    "    global TargetFile\n",
    "    global FileList\n",
    "    global SamplePeriod\n",
    "    global CsvDelim\n",
    "    global TotalTimeLength\n",
    "\n",
    "    \n",
    "    SamplePeriod = SamplePeriodFunction(FileList[TargetFile]) # Finds the Sample Period using the SamplePeriodFunction\n",
    "    SampleLength = np.loadtxt(\"./%s\"%(FileList[TargetFile]), delimiter=CsvDelim, usecols=1, skiprows=1) # load the data from the csv\n",
    "    A = SampleLength.shape # measure the shape to understand the number of y values\n",
    "    TotalTimeLength = round((A[0]*SamplePeriod),4) # turning the number of Y values into a time\n",
    "    #The following line generates the array between 0 and the time calculated above at an increment of the calculated sample period. \n",
    "    TimeArrayValues = np.arange(0,TotalTimeLength,SamplePeriod).round(decimals = 4) # Note the use of Round. This rounds the numbers generated for the time to a maximum of 4 decimal places. Stops float errors. \n",
    "    \n",
    "\n",
    "    return TimeArrayValues\n",
    "\n",
    "def Filtering(Data): # Applies a Savitzky - Golay filter to the waveform. Primarily to remove zero order hold sampling artifacts. \n",
    "    \n",
    "    global Time\n",
    "    global FilterTriggerWindowWidth\n",
    "    global MovingAverageWindowSize\n",
    "    \n",
    "    Data = signal.savgol_filter(Data, MovingAverageWindowSize, 1, mode=\"mirror\", deriv=0) # no phase shift filter to smooth out quantisation/sampling hold steps. \n",
    "    \n",
    "    return Data\n",
    "\n",
    "def BlankColumnProcessor(): # If the column to be processed is deemed blank a array of NaN values is generated. In reality this is unlikely to be used due to a length checker in the columnstoprocess variable. \n",
    "    \n",
    "    \n",
    "    global OutputDataFrame\n",
    "    global DataArray\n",
    "    global ChannelDescriptions\n",
    "    global YAxisScalingValuesExport\n",
    "\n",
    "    ProcessLabel = \"NO DATA\"\n",
    "     \n",
    "    Length = int(DataArray.shape[0]) # find length of currently generated DataArray to find the number of values required. \n",
    "        \n",
    "    ColumnData = np.empty(Length) # generate the Array.  \n",
    "    ColumnData[:] = np.nan # Populate with NaN values\n",
    "\n",
    "    DataArray = np.column_stack((DataArray,ColumnData)) # Add the existing DataArray\n",
    "\n",
    "    YAxisScalingValuesExport.append(0) # add values to the Y scaling list that is exported with the HDF5 File\n",
    "    YAxisScalingValuesExport.append(0)\n",
    "    ChannelDescriptions.append(ProcessLabel) # Add the string \"No Data\" to the label llist that is exported with the HDF5 file\n",
    "\n",
    "def ColumnProcessor(Column): # Processing each column, in the order identifed in the input and adding it to the DataFrame, Y value axis values and Labels as Column Headers generated and added to the respective list to be exported with the HDF5 File. \n",
    "    \n",
    "    global TargetFile\n",
    "    global FileList\n",
    "    global ScalingDictionary\n",
    "    global DataArray\n",
    "    global FilteringEnabled\n",
    "    global CsvDelim\n",
    "    global YAxisScalingValuesExport\n",
    "    global ChannelDescriptions\n",
    "    global ChannelUnits\n",
    "    global OriginalHeader\n",
    "   \n",
    "    # User Inputs\n",
    "    ProcessLabel = input(f\"\\nInput a label name/description for the data in Column {Column}, -  {OriginalHeader[Column-1][1:-1]}   ->   \")\n",
    "    ProcessUnit = input(f\"Define the unit of measurement for {ProcessLabel} -> \")\n",
    "\n",
    "    # Loading the relavent channal dataframe. \n",
    "    Column = int(Column)\n",
    "    ColumnData = np.loadtxt(\"./%s\"%(FileList[TargetFile]), delimiter=CsvDelim, usecols=Column, skiprows=1) # load the data from the csv\n",
    "\n",
    "    # Apply the Savitzky - Golay filter function if required.   \n",
    "    if FilteringEnabled == \"YES\" or FilteringEnabled == \"Yes\" or FilteringEnabled == \"yes\":\n",
    "        ColumnData = Filtering(ColumnData)  \n",
    "\n",
    "    # Round the floating value numbers to 4dp.     \n",
    "    ColumnData = ColumnData.round(decimals = 4)\n",
    "    \n",
    "    # Axis Scaling Values - Automatically estimate and then asks the user to agree or update. \n",
    "    \n",
    "    YminValue = round(float(np.nanmin(ColumnData[ColumnData != -np.inf])),4)  # finds the min value in the channel dataset but only looks at values that are not infinate. \n",
    "    YmaxValue = round(float(np.nanmax(ColumnData[ColumnData != np.inf])),4)     # Finds the Max Value\n",
    "        \n",
    "    YSpan = round((YmaxValue - YminValue),4) # finds the span of Y values (not including inf) from the min and max values\n",
    "    YAxisSpacingPercentEitherSide = 10 # variable to define the buffer either side ## MIGHT WANT TO ADJUST THIS\n",
    "    ValueBuffer = round(YSpan * (YAxisSpacingPercentEitherSide/100), 4) # calcultes this percentage as an actual value relative to the span. \n",
    "    Ymin = math.floor(YminValue - ValueBuffer) # finds the new min value, rounded down to the nearest number. \n",
    "    Ymax = math.ceil(YmaxValue + ValueBuffer) # finds the nex max value, rounded up to the nearest number. \n",
    "\n",
    "    \n",
    "    AxisChecker = input(f\"For Channel {ProcessLabel} the calculated Y axis min/max values are {Ymin} and {Ymax}, if you want to change these return any value other than a return ->   \")\n",
    "    if len(AxisChecker) != 0:\n",
    "        Ymin = round(float(input(f\"The automatic MIN Y axis value for data in Channel {ProcessLabel} is {Ymin}. Type in new value->   \")),2)\n",
    "        Ymax = round(float(input(f\"The automatic MAX Y axis value for data in Channel {ProcessLabel} is {Ymax}. Type in new value->   \")),2)\n",
    "\n",
    "    # Adds the additional information collected to the relavent lists. The idea is the index position for a given channel data is the same between all lists and the data array itself. \n",
    "\n",
    "    YAxisScalingValuesExport.append(Ymin)\n",
    "    YAxisScalingValuesExport.append(Ymax)\n",
    "    ChannelDescriptions.append(ProcessLabel)\n",
    "    ChannelUnits.append(ProcessUnit)\n",
    "\n",
    "    # Adds the Array to the existing DataArray as an additional column. \n",
    "\n",
    "    DataArray = np.column_stack((DataArray,ColumnData))\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files located within ./Input_CSV_Files\n",
      "File 1 = TestFile1.csv\n",
      "File 2 = TestFile2.csv\n",
      "File 3 = TestFile3.csv\n"
     ]
    }
   ],
   "source": [
    "# FILE SELECTION - CSV Data Location / List. Generates list of files within the defined folder. \n",
    "\n",
    "# Constants\n",
    "\n",
    "CsvDelim = \";\" # delimter within cvs\n",
    "InputFolder = \"./Input_CSV_Files\" # input file path\n",
    "HDF5OutputFilePath = \"Processed_HDF5_Files\" # Output Folder\n",
    "\n",
    "# Code\n",
    "\n",
    "print(f\"Files located within {InputFolder}\") # Header\n",
    "FileList = [f for f in os.listdir(InputFolder) if isfile(join(InputFolder, f))] # look through the folder specified in the variable above and generate a list of all the files within that folder. \n",
    "InputFolder = InputFolder[2:] + \"/\" # conerting the file path input constant to work correctly with susequent open/import requests\n",
    "FileList = [InputFolder + s for s in FileList] # Adds the filepath to the file name so it can be easily used by following import/open functions to all the values in the list. (for each list element in FileList (S), add the element to the end of the ImportFolder string. Return as a list element)\n",
    "FileListCounter = 1 # Counter for print loop below\n",
    "for I in FileList: # printing the csv datasets within the folder - makes it easier to select the desired file\n",
    "    print(f\"File {FileListCounter} = {I[16:]}\")\n",
    "    FileListCounter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Channel 1 = 1__1_2500_044_Engine_Speed__ECU_\n",
      "Channel 2 = 1__1_0181_001_P_Charge_Mix_A\n",
      "Channel 3 = 1__1_4540_007_Fuel_Flow\n"
     ]
    }
   ],
   "source": [
    "TargetFile = input(\"\\nWhich file to process? Input a integer value between 1 & %s  ->   \"%(len(FileList)))  # asks the question about which file to process. Wants an input. \n",
    "\n",
    "#TargetFile = \"9\" #Default for test purposes\n",
    "\n",
    "TargetFile = NumberCheck(TargetFile) # Checking the value inputted is a number. \n",
    "TargetFile = int(TargetFile)-1 # the minus one is to convert the inputted value (converted into an int), 1, 2 etc into a index position for the list. \n",
    "if TargetFile > (len(FileList)-1) or TargetFile == -1: # Checking that the value is actually a legit value, ie that there is a list index position for the number inputted or that 0 hasnt been inputted\n",
    "    print(\"The number entered is greater than the number of dataset files available\")\n",
    "    input(\"Press any key to exit  \") # A way to pause the program and ensure the user understands why the program is about to stop. \n",
    "    quit() # Stops the program. \n",
    "\n",
    "\n",
    "OriginalFile = open(\"./%s\"%(FileList[TargetFile]), \"r\") # opens the target file\n",
    "OriginalHeader = OriginalFile.readline() # read a line from the document. Python behind the scenes knows the read the next line when its next run\n",
    "OriginalHeader = OriginalHeader.strip() # the strip removes the return for new line (/n) from the string.\n",
    "OriginalFile.close() # close the file. must do. \n",
    "OriginalHeader = OriginalHeader.split(\";\") # split the string into a list using the sepeartor ;\n",
    "OriginalHeader.pop(0) # deletes the first element in the Original Header list - ie the TIME column. \n",
    "OriginalHeaderCounter = 1 # counter for printing loop below. \n",
    "print(\"\") # Generates a space in the terminal - used to help userability. \n",
    "for a in OriginalHeader:\n",
    "    print(f\"Channel {OriginalHeaderCounter} = {a[1:-1]}\") # f function to print two variables inline\n",
    "    OriginalHeaderCounter +=1 # counter for channel number in print function. \n",
    "#print(\"\") # Ganerates a space in the terminal. Unsure if required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the columns to process. Checks that the inputted values are within the number of potential selectable columns. \n",
    "\n",
    "ColumnInputString = input(\"\\nWhich channels to process - %s Channels to select from - State channel number in the desired order. \\nChannel 0 results in a channel array of NaN's (Use if your missing a channel in the oringial file). Input integers and spaces only - eg. 1 21 3..... for exmaple ->   \"%(len(OriginalHeader))) # input for the desired columns to import in the order desired. \n",
    "#ColumnInputString = \"5\" # Default for testing purposes\n",
    "ColumnsToProcess = ColumnInputString.split(\" \") # splitting string full of numbers (hopfully) into a list. \n",
    "ColumnsToProcess = NumberCheck(ColumnsToProcess) # checking that all the values in the list are actually numbers\n",
    "\n",
    "for CP in ColumnsToProcess: # checking that the numbers within that list are actual channels\n",
    "    if int(CP) > len(OriginalHeader): #or int(CP) == 0: # if the value in the list is greater than the length of potential columns program stops in the same way as above.\n",
    "        print(\"The number entered is greater than the number of datasets available\")\n",
    "        input(\"Press any key to exit  \")\n",
    "        quit()\n",
    "\n",
    "# Is filtering required. If so define the filter window. \n",
    "\n",
    "FilteringEnabled = input(\"\\nDo you want to apply Savitzky Golay Filtering to the sample if Zero-Order sampling values are detected? Yes or No ->   \")\n",
    "\n",
    "if FilteringEnabled == \"YES\" or FilteringEnabled == \"Yes\" or FilteringEnabled == \"yes\":\n",
    "    #FilterTriggerWindowWidth = input(\"Define the window width you want to try identify Zero-Order sampling across. Default is 20. ->   \")    # This was previously used to try and identify Zero Order Sampling artifacts. Not used. User decides if to filter or not. \n",
    "    #FilterTriggerWindowWidth = InputVariableNumberChecker(FilterTriggerWindowWidth, 20)\n",
    "    MovingAverageWindowSize = input(\"Define the window size for the Savitzky Golay Filter. Default is 60. ->   \")\n",
    "    MovingAverageWindowSize = InputVariableNumberChecker(MovingAverageWindowSize, 60)\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataArray = TimeArray() # Generates the Time array using the function defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up additional information lists\n",
    "\n",
    "YAxisScalingValuesExport = []\n",
    "ChannelDescriptions = []\n",
    "ChannelUnits = []\n",
    "\n",
    "# Main processing loop. For each column defined by the user to be processed (in the order inputted) scrap the data from the input csv and add it to the DataFrame. \n",
    "\n",
    "for ColumnItem in ColumnsToProcess: \n",
    "    ColumnItem = int(ColumnItem)\n",
    "    if ColumnItem == 0:\n",
    "        BlankColumnProcessor()\n",
    "    else:\n",
    "        ColumnProcessor(ColumnItem) # The function is defines above. \n",
    "\n",
    "#Delete the time column from the data array. - Saves space. Not needed considering the sample time is sent wtih the HDF5 file. \n",
    "DataArray = np.delete(DataArray,0,1) \n",
    "\n",
    "\n",
    "# Generating / Collecting the desired file output name. Either takes a user inputted string or the original filename. \n",
    "\n",
    "DefaultOutputFileName = FileList[TargetFile]\n",
    "DefaultOutputFileName = DefaultOutputFileName[16:-4]\n",
    "\n",
    "OutputFileName = input(\"Type in the desired output File name. %s.hdf5 is the default filename if no string is inputted ->   \"%(DefaultOutputFileName))\n",
    "if len(OutputFileName) == 0: # Used to detect if nothing was inputted, ie to use the default value. \n",
    "    OutputFileName = DefaultOutputFileName\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Additional Information saved within the HDF5 File ----\n",
      "Engine Speed\n",
      "A Bank Inlet Manifold\n",
      "Fuel Flow\n",
      "This recording is 62.9 seconds long with a sample period of 0.005 seconds.\n",
      "No Filter was applied to this dataset\n",
      "This dataset was processed from the oringial file - TestFile1.csv\n",
      "This file was generated with Version 2 of the DiaSys CSV HDF5 Processor Script on 13 August 2024.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Additional Info to save with the file as aditional information. \n",
    "\n",
    "ScriptVersionInfo = \"This file was generated with Version %s of the DiaSys CSV HDF5 Processor Script on %s.\"% (Version, date.today().strftime(\"%d %B %Y\"))\n",
    "OriginalImportFile = \"This dataset was processed from the oringial file - %s\"%(FileList[TargetFile][16:])\n",
    "if FilteringEnabled == \"YES\" or FilteringEnabled == \"Yes\" or FilteringEnabled == \"yes\":\n",
    "    FilteringInfo = \"A Savitzky Golay Filter was applied to this dataset using a window size of %s.\"%(MovingAverageWindowSize)\n",
    "else:\n",
    "    FilteringInfo = \"No Filter was applied to this dataset\"\n",
    "TimeInfo = \"This recording is %s seconds long with a sample period of %s seconds.\"%(TotalTimeLength,SamplePeriod)\n",
    "\n",
    "FileDescription = [TimeInfo,FilteringInfo,OriginalImportFile,ScriptVersionInfo]\n",
    "\n",
    "print (\"\\n---- Additional Information saved within the HDF5 File ----\")\n",
    "for Instance in ChannelDescriptions:\n",
    "    print(Instance)\n",
    "for Instance in FileDescription:\n",
    "    print(Instance)\n",
    "\n",
    "# Saving the HDF5 File. \n",
    "\n",
    "SaveFile = h5py.File(\"%s/%s.hdf5\"% (HDF5OutputFilePath, OutputFileName), \"w\") # Generating the hdf5 file\n",
    "SaveFile[\"Data\"] = DataArray #saving the Dataset variable to a part of the file called Data \n",
    "SaveFile[\"Data\"].attrs[\"Info\"] = FileDescription # defining an attribute of that saved file with the key Info - File information. \n",
    "SaveFile[\"Data\"].attrs[\"ChannelDescriptions\"] = ChannelDescriptions # exported in sequence\n",
    "SaveFile[\"Data\"].attrs[\"ChannelUnits\"] = ChannelUnits # exported in sequence\n",
    "SaveFile[\"Data\"].attrs[\"YScales\"] = YAxisScalingValuesExport # exported in sequence (A Ymin, A Ymax, B Ymin, B Ymax.....)\n",
    "SaveFile[\"Data\"].attrs[\"SamplePeriod\"] = SamplePeriod # Exported as int value. \n",
    "SaveFile[\"Data\"].attrs[\"SampleLength\"] = TotalTimeLength # Exporting an float of the length of the recording (in seconds)\n",
    "SaveFile.close() # closing the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
